# Pattern Recognition and Object Detection 2022

Students: JaoKha, Kwan, and Reuben

  * W1: course introduction, overview of pattern recognition and predictive model
  * W2: introduction to optimization
  * W3: introduction to ML, curve fitting and model selection
  * W4: introduction to ANN
  * W5: paper reading
  * W6: Hands-On: SSD
    * https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html
    * https://colab.research.google.com/drive/1qDGZVog_veNqs5QcLDrv1ew99TcDCIMY#scrollTo=5v5S3bm07SO1
      * TO DO: 
        * 1. Modify it to SSD
          * train SSD https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD#getting-the-data 
            *  
        * 2. Try other model from model zoo
          * https://github.com/NVIDIA/DeepLearningExamples 
          * https://pytorch.org/hub
        * 3. Try put it customized data

  * Docker container accesses GPU
    * https://stackoverflow.com/questions/25185405/using-gpu-from-a-docker-container
    * https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD#getting-the-data
      * excerpt from Quick Start Guide section
        * ```docker build . -t nvidia_ssd``` 
        * ```docker run --rm -it --gpus=all --ipc=host -v $COCO_DIR:/coco nvidia_ssd```
    * https://docs.docker.com/compose/gpu-support/
    * https://www.docker.com/blog/wsl-2-gpu-support-for-docker-desktop-on-nvidia-gpus/ 
    * https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch
      * https://github.com/NVIDIA/nvidia-docker 
        * https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker 
        * Done! test with ```sudo docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi```


## Log

### Sep 11, 2022.
* Allow non-root user to access docker
```sudo usermod -aG docker [non-root user]```
* Login as a user
```sudo su [user]```

### July 12th, 2022.
  * [Continue trying Nvidia SSD](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD#getting-the-data)
    * Quick Start Guide section: run ```docker build . -t nvidia_ssd```
      * ```-t``` is "Name and optionally a tag in the 'name:tag' format" ([from docker doc](https://docs.docker.com/engine/reference/commandline/build/))
      * It takes very long time to run this command: reach 
      * [Dockerfile](https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/Detection/SSD/Dockerfile) and [requirements.txt](https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/Detection/SSD/requirements.txt)
      * retry again with ```nohup docker build . -t nvidia_ssd1 &```
        * TO DO: remove ```nvidia_ssd```, which may be incomplete, since I press <ctrl>+C while on ```COPY . .```

### July 13th, 2022
  * Command ```nohup docker build . -t nvidia_ssd1 &``` does not seem to work. The process has been stopped, but no ```nvidia_ssd1``` has been created.
  * Rename old half-baked image to ```nvidia_ssd0``` and try to finish up the ```COPY . .```
    * ```docker run --rm -it --gpus=all --ipc=host -v ~/2022/nvidia_examples/PyTorch/Detection:/Detection nvidia_ssd0```
    * ```cd /workspace/ssd``` then ```cp /Detection/* .```
    * Folders did not get copied over. 
      * Fix with ```cp -r /Detection/SSD/COCO .```
      * Fix with ```cp -r /Detection/SSD/dle .```
      * Fix with ```cp -r /Detection/SSD/examples .``` 
      * Fix with ```cp -r /Detection/SSD/img .```    
      * Fix with ```cp -r /Detection/SSD/ssd .```    
    * I forgot that it is not persistent.
 * Commit container of ```nvidia_ssd0``` to ```nvidia_ssd1```, then copy files over.
   * On ```Detection/SSD```, run ```docker cp . <container id>:/workspace/ssd```
     * Note: <container id> has to be **containter id**. It cannot be image name. Otherwise, it will give "no such container!".
   * Finally, once files are copied over, don't forget to **commit** a container to an image.

 * DOING:
   * Test docker image ```nvidia_ssd``` (once it is good, remove older images: ```nvidia_ssd0```, ```nvidia_ssd1```)
   * In ```/workspace/ssd``` of the container, test training: 
     * ```bash ./examples/SSD300_FP16_8GPU.sh . ./COCO --save ./SSD_CHECKPOINT```
     * where ```SSD_CHECKPOINT``` has been created under ```/workspace/ssd```.
     * Result:
       * ```RuntimeError: CUDA error: invalid device ordinal```
     * Try again with ```bash ./examples/SSD300_FP16_1GPU.sh . ./COCO --save ./SSD_CHECKPOINT``` (for 1 GPU)
       * Result: it has been 9 hours (I started around noon, now is 9pm) and it is still running!
       * I stopped it.
     * At Jul 13 14:59 (Bach time), re-start with ```bash ./examples/SSD300_FP16_1GPU.sh . ./COCO --save /sandbox >> /sandbox/log``` so that I'll have the output saved in host ```~/2022/sandbox```. The estimated time is logged (in nvidia code).
       * PIDs: 334, 342
       * All network programs (vpn, putty, filezilla) have stopped after about 15 hours of running.
       * Each epoch spends about 30 min.
       * Next (c.f. run directly from docker) but wait (cause it seems to have python process running host pid 13849)
         * ```docker run --rm -it --gpus=all --ipc=host -v <host mounting point>:<container mounting point> nvidia_ssd ./trainscript``` where ```./trainscript``` is runable script to evoke ```main.py``` properly (from host perspective)

     * Once it's done: make a copy of the image: ```docker save -o ./nvidia_ssd.tar nvidia_ssd```
       * This tar file can be loaded by a new system using ```docker load -i <path to image tar file>```
 
   * test inference:
     * Steps 6-8 under [Quick Start Guide](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD#quick-start-guide)
